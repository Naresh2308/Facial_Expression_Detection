# -*- coding: utf-8 -*-
"""Face_expression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10IsclsRkZjpoKQ6_6pXw103tesZlmmEW
"""

!pip install kaggle

!kaggle datasets download -d apollo2506/facial-recognition-dataset --unzip -p /content/dataset

!ls /content/dataset

import os

dataset_dir = '/content/dataset'
image_files = [f for f in os.listdir(dataset_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]

print(f"Found {len(image_files)} image files.")

!mv /content/dataset/Testing/Testing/* /content/dataset/Testing/
!rm -r /content/dataset/Testing/Testing

from PIL import Image, UnidentifiedImageError
import matplotlib.pyplot as plt
import os

# Define the updated Testing directory
testing_dir = '/content/dataset/Testing'

# Check if the Testing directory exists
if not os.path.exists(testing_dir):
    print(f"Directory not found: {testing_dir}")
else:
    # Loop through each class folder in the Testing directory
    for class_name in os.listdir(testing_dir):
        class_path = os.path.join(testing_dir, class_name)

        # Ensure the path is a directory (class folder)
        if os.path.isdir(class_path):
            print(f"Class: {class_name}")

            # Display the first 5 images in the class folder
            for image_name in os.listdir(class_path)[:5]:
                image_path = os.path.join(class_path, image_name)

                # Attempt to open and display the image
                try:
                    with Image.open(image_path) as image:
                        plt.figure()
                        plt.imshow(image)
                        plt.title(f"Class: {class_name}, Image: {image_name}")
                        plt.axis('off')
                        plt.show()
                except UnidentifiedImageError:
                    print(f"File {image_name} is not a valid image.")
                except Exception as e:
                    print(f"Error loading {image_name}: {e}")
        else:
            print(f"Skipping non-directory file: {class_name}")

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import regularizers
from tensorflow.keras.utils import to_categorical, load_img # Import load_img from tensorflow.keras.utils
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, BatchNormalization
import os
import pandas as pd
import numpy as np

!mv /content/dataset/Training/Training/* /content/dataset/Training/
!rm -r /content/dataset/Training/Training

TRAIN_DIR = '/content/dataset/Training'
TEST_DIR = '/content/dataset/Testing'

def createdataframe(dir):
    image_paths = []
    labels = []
    for label in os.listdir(dir):
        for imagename in os.listdir(os.path.join(dir,label)):
            image_paths.append(os.path.join(dir,label,imagename))
            labels.append(label)
        print(label, "completed")
    return image_paths,labels

train = pd.DataFrame()
train['image'], train['label'] = createdataframe(TRAIN_DIR)

print(train)

test = pd.DataFrame()
test['image'], test['label'] = createdataframe(TEST_DIR)

print(test)
print(test['image'])

from tqdm.notebook import tqdm

def extract_features(images):
    features = []
    for image in tqdm(images):
        img = load_img(image,color_mode= 'grayscale')
        img = np.array(img)
        features.append(img)
    features = np.array(features)
    features = features.reshape(len(features),48,48,1)
    return features

train_features = extract_features(train['image'])

test_features = extract_features(test['image'])

x_train = train_features/255.0
x_test = test_features/255.0

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
le.fit(train['label'])

y_train = le.transform(train['label'])
y_test = le.transform(test['label'])

y_train = to_categorical(y_train,num_classes = 7)
y_test = to_categorical(y_test,num_classes = 7)

# model = Sequential()


# model.add(Conv2D(64,(3,3), padding='same',activation='relu', input_shape=(48, 48,1)))
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Dropout(0.25))

# # 2nd Convolution layer
# model.add(Conv2D(128,(5,5),activation='relu', padding='same'))
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Dropout(0.25))

# # 3rd Convolution layer
# model.add(Conv2D(512,(3,3),activation='relu', padding='same'))
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Dropout(0.25))

# # 4th Convolution layer
# model.add(Conv2D(512,(3,3),activation='relu', padding='same'))
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Dropout(0.25))
# model.add(Conv2D(64,(3,3), padding='same',activation='relu', input_shape=(48, 48,1)))
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Dropout(0.25))

# # 2nd Convolution layer
# model.add(Conv2D(128,(5,5),activation='relu', padding='same'))
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Dropout(0.25))

# # 3rd Convolution layer
# model.add(Conv2D(512,(3,3),activation='relu', padding='same'))
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Dropout(0.25))

# # 4th Convolution layer
# model.add(Conv2D(512,(3,3),activation='relu', padding='same'))
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Dropout(0.25))


# # Flattening
# model.add(Flatten())

# model.add(Dense(256,activation='relu'))
# model.add(Dropout(0.25))

# # Fully connected layer 2nd layer
# model.add(Dense(512,activation='relu'))
# model.add(Dropout(0.25))

# model.add(Dense(7, activation='softmax'))


# # convolutional layers
# model.add(Conv2D(128, kernel_size=(3,3), activation='relu', input_shape=(48,48,1)))
# model.add(MaxPooling2D(pool_size=(2,2)))
# model.add(Dropout(0.2))

# model.add(Conv2D(256, kernel_size=(3,3), activation='relu',))
# model.add(MaxPooling2D(pool_size=(2,2)))
# model.add(Dropout(0.3))

# model.add(Conv2D(512, kernel_size=(3,3), activation='relu'))
# model.add(MaxPooling2D(pool_size=(2,2)))
# model.add(Dropout(0.4))


# model.add(Flatten())
# # fully connected layers
# model.add(Dense(512, activation='relu'))
# model.add(Dropout(0.4))
# model.add(Dense(256, activation='relu'))
# model.add(Dropout(0.3))
# model.add(Dense(128, activation='relu'))
# model.add(Dropout(0.3))
# model.add(Dense(64, activation='relu'))
# model.add(Dropout(0.3))
# model.add(Dense(32, activation='relu'))
# model.add(Dropout(0.3))

# # output layer
# model.add(Dense(7, activation='softmax'))

model = Sequential()


model.add(Conv2D(64,(3,3), padding='same',activation='relu', input_shape=(48, 48,1)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

# 2nd Convolution layer
model.add(Conv2D(128,(5,5),activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

# 3rd Convolution layer
model.add(Conv2D(512,(3,3),activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

# 4th Convolution layer
model.add(Conv2D(512,(3,3),activation='relu', padding='same'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

# Flattening
model.add(Flatten())

model.add(Dense(256,activation='relu'))
model.add(Dropout(0.25))

# Fully connected layer 2nd layer
model.add(Dense(512,activation='relu'))
model.add(Dropout(0.25))

model.add(Dense(7, activation='softmax'))

datagen = ImageDataGenerator(
    rotation_range=20,  # Rotate images by up to 20 degrees
    width_shift_range=0.2,  # Shift images horizontally by up to 20% of the width
    height_shift_range=0.2,  # Shift images vertically by up to 20% of the height
    shear_range=0.2,  # Apply shear transformations
    zoom_range=0.2,  # Zoom in/out on images
    horizontal_flip=True,  # Flip images horizontally
    fill_mode='nearest'  # Fill any empty pixels with nearest neighbor values
)

datagen.fit(x_train)

# model = Sequential()

# model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(48, 48, 1),kernel_regularizer=regularizers.l2(0.01)))
# model.add(BatchNormalization())
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Dropout(0.25))

# model.add(Conv2D(64, (5, 5), activation='relu', padding='same', kernel_regularizer=regularizers.l1(0.01)))
# model.add(BatchNormalization())
# model.add(MaxPooling2D(pool_size=(2, 2)))
# model.add(Dropout(0.25))

# model.add(Flatten())
# model.add(Dense(256, activation='relu'))
# model.add(Dropout(0.3))
# model.add(Dense(7, activation='softmax'))

model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'] )

model.summary()

from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

model.fit(x=x_train, y=y_train, batch_size=64, epochs=50,
          validation_data=(x_test, y_test), callbacks=[early_stopping])

model_json = model.to_json()
with open("emotiondetector.json",'w') as json_file:
    json_file.write(model_json)
model.save("emotiondetector.h5")

from keras.models import model_from_json

json_file = open("emotiondetector.json", "r")
model_json = json_file.read()
json_file.close()
model = model_from_json(model_json)
model.load_weights("emotiondetector.h5")

label = ['angry','fear','happy','neutral','sad','surprise']

def ef(image):
    img = load_img(image,color_mode='grayscale' )
    feature = np.array(img)
    feature = feature.reshape(1,48,48,1)
    return feature/255.0

image = '/content/dataset/Testing/Suprise/Suprise-100.jpg'
# print("original image is of angry")
img = ef(image)
pred = model.predict(img)
pred_label = label[pred.argmax()]
print("model prediction is ",pred_label)

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

image = '/content/dataset/Testing/Fear/Fear-1001.jpg'
# print("original image is of happy")
img = ef(image)
pred = model.predict(img)
pred_label = label[pred.argmax()]
print("model prediction is ",pred_label)
plt.imshow(img.reshape(48,48),cmap='gray')

# 1. Import necessary libraries
from sklearn.metrics import confusion_matrix
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# 2. Predict on the test set
y_pred = model.predict(x_test)

# 3. Get predicted labels (numerical format)
y_pred_classes = np.argmax(y_pred, axis=1)

# 4. Get true labels (numerical format)
y_true_classes = np.argmax(y_test, axis=1)

# 5. Compute the confusion matrix
cm = confusion_matrix(y_true_classes, y_pred_classes)

# 6. Display the confusion matrix using a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=label, yticklabels=label)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

from google.colab import drive
drive.mount('/content/drive')

import cv2
import matplotlib.pyplot as plt

image_path = "/content/drive/MyDrive/WhatsApp Image 2025-02-02 at 22.52.48_a67d6531.jpg"
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB

plt.imshow(image)
plt.axis('off')  # Hide axes
plt.show()

def ef1(image):
    img = load_img(image,color_mode='grayscale', target_size=(48, 48)) # Resize the image
    feature = np.array(img)
    feature = feature.reshape(1,48,48,1)
    return feature/255.0

image = '/content/drive/MyDrive/WhatsApp Image 2025-02-02 at 22.52.48_a67d6531.jpg'
# print("original image is of happy")
img = ef1(image)
pred = model.predict(img)
pred_label = label[pred.argmax()]
print("model prediction is ",pred_label)
plt.imshow(img.reshape(48,48),cmap='gray')

